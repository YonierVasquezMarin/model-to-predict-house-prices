{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emplear Regresión Por Maquina de Soporte de Vectores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traer los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener los datos de las viviendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data():\n",
    "    csv_path = os.path.join(\"datasets\", \"housing\", \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los conjuntos de training y testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar categorias para el ingreso medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(\n",
    "    housing[\"median_income\"],\n",
    "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "    labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    4\n",
       "4    3\n",
       "Name: income_cat, dtype: category\n",
       "Categories (5, int64): [1 < 2 < 3 < 4 < 5]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"income_cat\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir el conjunto de datos en dos subconjuntos, uno para entrenamiento y otro para pruebas. Ambos de forma estratificada en base a un atributo importante (que las categorias de ingresos sean proporcionales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Dividir los dos conjuntos proporcionalmente a la categoria de ingresos\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# Eliminar la columna de categoria, ya no es necesaria\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasignar a \"housing\" los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar transformadores para limpieza y desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, x, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, x):\n",
    "        rooms_per_household = x[:, rooms_ix] / x[:, households_ix]\n",
    "        population_per_household = x[:, population_ix] / x[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = x[:, bedrooms_ix] / x[:, rooms_ix]\n",
    "            return np.c_[x, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[x, rooms_per_household, population_per_household]\n",
    "        \n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades para el entrenamiento\n",
    "Funciones para guardar en un archivo el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from enum import Enum\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Model(Enum):\n",
    "    REGRESSION = 1\n",
    "    DECISION_TREE_REGRESSION = 2\n",
    "    RANDOM_FOREST_REGRESSION = 3\n",
    "\n",
    "path_models_saved = \"models_saved\"\n",
    "extension = \".joblib\"\n",
    "\n",
    "def get_object_saved_full_filename(model_name):\n",
    "    return os.path.join(path_models_saved, model_name+extension)\n",
    "\n",
    "def create_models_directory_if_not_exist():\n",
    "    os.makedirs(path_models_saved, exist_ok=True)\n",
    "\n",
    "def save_object(object, filename):\n",
    "    full_path = get_object_saved_full_filename(filename)\n",
    "    joblib.dump(object, full_path)\n",
    "\n",
    "def object_is_saved(filename):\n",
    "    full_path = get_object_saved_full_filename(filename)\n",
    "    return os.path.exists(full_path)\n",
    "\n",
    "def get_object_saved(filename):\n",
    "    if object_is_saved(filename):\n",
    "        full_path = get_object_saved_full_filename(filename)\n",
    "        return joblib.load(full_path)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def create_model_fit_and_save_it(filename, model_type, train_data, label_data):\n",
    "    if model_type == Model.REGRESSION:\n",
    "        new_model = LinearRegression()\n",
    "    if model_type == Model.DECISION_TREE_REGRESSION:\n",
    "        new_model = DecisionTreeRegressor()\n",
    "    if model_type == Model.RANDOM_FOREST_REGRESSION:\n",
    "        new_model = RandomForestRegressor()\n",
    "    new_model.fit(train_data, label_data)\n",
    "    save_object(new_model, filename)\n",
    "    \n",
    "\n",
    "def create_model_or_get_it_if_is_saved(filename, model_type, train_data, label_data):\n",
    "    if object_is_saved(filename) == False:\n",
    "        create_model_fit_and_save_it(filename, model_type, train_data, label_data)\n",
    "    return get_object_saved(filename)\n",
    "        \n",
    "def create_cross_validation_and_save(model, filename, train_data, label_data):\n",
    "    new_cross_validation = cross_val_score(model, train_data, label_data, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    save_object(new_cross_validation, filename)\n",
    "\n",
    "def create_cross_validation_or_get_it_if_is_saved(model, filename, train_data, label_data):\n",
    "    if object_is_saved(filename) == False:\n",
    "        create_cross_validation_and_save(model, filename, train_data, label_data)\n",
    "    return get_object_saved(filename)\n",
    "    \n",
    "create_models_directory_if_not_exist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicar el modelo RandomForestRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor rendimiento (el error más bajo) hasta el momento se logró son RandomForestRegressor. La siguiente es una tabla de RMSE.\n",
    "|    LinealReg   |     TreeReg    |  RandomForest  |\n",
    "|     :----:     |     :----:     |    :----:      |\n",
    "|     68627.87   |     71035.40   |    18576.97    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conocer el nivel de error del RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18635.99791978067"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "forest_reg = create_model_or_get_it_if_is_saved(\n",
    "    \"housing_random_forest_reg_v1\",\n",
    "    Model.RANDOM_FOREST_REGRESSION,\n",
    "    housing_prepared,\n",
    "    housing_labels)\n",
    "\n",
    "housing_predicts_forest = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predicts_forest)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estadisticas de ejecución en de RandomForestRegressor en local y remoto.\n",
    "\n",
    "| Local | Remoto |\n",
    "| :----: | :----: |\n",
    "| 22s | 18s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformador para las mejores propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conocer las mejores propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.47308395557897825, 'median_income'),\n",
       " (0.14014098769042466, 'INLAND'),\n",
       " (0.12228755505877409, 'pop_per_hold'),\n",
       " (0.05843995294323259, 'longitude'),\n",
       " (0.055840958756697194, 'latitude'),\n",
       " (0.04499531762593821, 'housing_median_age'),\n",
       " (0.027676788393301982, 'rooms_per_hold'),\n",
       " (0.023099261870226283, 'bedrooms_per_room'),\n",
       " (0.01293876685551241, 'total_rooms'),\n",
       " (0.012477742664262005, 'households'),\n",
       " (0.012381544673676536, 'population'),\n",
       " (0.012338078471531646, 'total_bedrooms'),\n",
       " (0.0022293698561331073, 'NEAR OCEAN'),\n",
       " (0.0011538869616731836, '<1H OCEAN'),\n",
       " (0.0008401694208750632, 'NEAR BAY'),\n",
       " (7.566317876275575e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = forest_reg.feature_importances_\n",
    "\n",
    "# propiedades generadas por el transformador\n",
    "extra_attribs = [\"rooms_per_hold\", \"pop_per_hold\", \"bedrooms_per_room\"]\n",
    "\n",
    "# columnas one-hot de las categorias de ocean_proximity\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "\n",
    "# asocia el nombre de la columna con su importancia y lo ordena de mayor a menor\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición del transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    '''Indices del array k valores mas grandes.'''\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        '''Dada la matriz, solo toma las columnas de los indices mas importantes. (solo funciona con numpy)'''\n",
    "        return x[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallar los indices de las características más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['longitude', 'latitude', 'median_income', 'pop_per_hold', 'INLAND'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5 # number of top features to select\n",
    "\n",
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "np.array(attributes)[top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicación del transformador de mejores propiedades a los demas transformadores y entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar el nuevo transformador a una nueva instancia de `RandomForestRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_v2 = preparation_and_feature_selection_pipeline.fit_transform(housing)\n",
    "\n",
    "forest_reg_v2 = create_model_or_get_it_if_is_saved(\n",
    "    \"housing_random_forest_reg_v2\",\n",
    "    Model.RANDOM_FOREST_REGRESSION,\n",
    "    housing_prepared_v2,\n",
    "    housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallar el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18984.351788109732"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predicts_forest_v2 = forest_reg_v2.predict(housing_prepared_v2)\n",
    "forest_mse_v2 = mean_squared_error(housing_labels, housing_predicts_forest_v2)\n",
    "forest_rmse_v2 = np.sqrt(forest_mse_v2)\n",
    "forest_rmse_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión: la reducción de características no redujo el error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
